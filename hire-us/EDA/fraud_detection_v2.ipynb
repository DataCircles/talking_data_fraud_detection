{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fraud_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "VadoVb6N4d-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import gc\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "# import os\n",
        "# print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOkmlCoKJEbn",
        "colab_type": "code",
        "outputId": "0b2bd947-b808-4076-dae5-fa338aaa3b3c",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4ce96dc3-2ff1-440a-9252-2a1a34489a92\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4ce96dc3-2ff1-440a-9252-2a1a34489a92\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"botatu\",\"key\":\"67288ace4f6e83162f50d94e0dab13eb\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKdWnvO2NmMc",
        "colab_type": "code",
        "outputId": "908af5a7-bd80-42db-8f2c-775692819b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQCxIIX7Ka2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip freeze\n",
        "!pip install -q kaggle-cli"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBclo9PpK_QH",
        "colab_type": "code",
        "outputId": "b242644b-c44e-4ac4-ec83-7528dab5b462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!kaggle competitions download -c talkingdata-adtracking-fraud-detection -f train_sample.csv\n",
        "!kaggle competitions download -c talkingdata-adtracking-fraud-detection -f test.csv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train_sample.csv.zip to /content\n",
            "\r  0% 0.00/1.08M [00:00<?, ?B/s]\n",
            "100% 1.08M/1.08M [00:00<00:00, 71.8MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 92% 152M/165M [00:01<00:00, 127MB/s]\n",
            "100% 165M/165M [00:01<00:00, 135MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijRTFPYOOLQn",
        "colab_type": "code",
        "outputId": "59525ddf-74c4-42dc-d21d-242dfc3a30bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip train_sample.csv.zip\n",
        "# !unzip train.csv.zip\n",
        "!unzip test.csv.zip\n",
        "# !unzip sample_submission.csv.zip\n",
        "# !unzip test_supplement.csv.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train_sample.csv.zip\n",
            "replace mnt/ssd/kaggle-talkingdata2/competition_files/train_sample.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "Archive:  test.csv.zip\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1sgdWdsPQnf",
        "colab_type": "code",
        "outputId": "46ba1bb4-eafc-46c9-b36b-413bce8febf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!rm train_sample.csv.zip sample_submission.csv.zip test.csv.zip test_supplement.csv.zip train.csv.zip sample_submission.csv\n",
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'sample_submission.csv.zip': No such file or directory\n",
            "rm: cannot remove 'test_supplement.csv.zip': No such file or directory\n",
            "rm: cannot remove 'train.csv.zip': No such file or directory\n",
            "rm: cannot remove 'sample_submission.csv': No such file or directory\n",
            "'kaggle (1).json'   kaggle.json   mnt   sample_data   test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pazu_nZ2nBuh",
        "colab_type": "code",
        "outputId": "7fecf652-b513-4c47-932c-3b15653c88f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls mnt/ssd/kaggle-talkingdata2/competition_files/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_sample.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4Fn3wPa33yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add/update the count of a column at given index on a rolling basis\n",
        "def update_count(index, data_till_now, train_data, col_name, count_col_name):\n",
        "  col_value = train_data.iloc[index][col_name]\n",
        "  prev_ip_rows = data_till_now[data_till_now[col_name]==col_value]\n",
        "  if len(prev_ip_rows) > 0:\n",
        "    train_data.at[index, count_col_name] = prev_ip_rows.iloc[-1][count_col_name] + 1\n",
        "  else:\n",
        "    train_data.at[index, count_col_name] = 1\n",
        "  \n",
        "\n",
        "def update_attribution_percentage(data_till_now, train_data, col_name, percentage_col_name, count_col_name):\n",
        "  col_value = train_data.iloc[index][col_name]\n",
        "  is_attributed_sum = data_till_now[data_till_now[col_name]==col_value]['is_attributed'].sum()\n",
        "  if is_attributed_sum == 0:\n",
        "    train_data.at[index, percentage_col_name] = 0\n",
        "  else:\n",
        "    train_data.at[index, percentage_col_name] = is_attributed_sum/(train_data.at[index, count_col_name])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aYbEfUNWsML",
        "colab_type": "code",
        "outputId": "d555ab23-7b3a-4cc4-a6da-3b6e4f709ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "source": [
        "dtypes = {  'ip': 'uint16',\n",
        "            'app': 'uint16',\n",
        "            'device': 'uint16',\n",
        "            'os': 'uint16',\n",
        "            'channel': 'uint16',\n",
        "            'is_attributed': 'uint8'}\n",
        "\n",
        "chunk_size=1000\n",
        "train_data = pd.DataFrame()\n",
        "start_index = 0\n",
        "for chunk in pd.read_csv('mnt/ssd/kaggle-talkingdata2/competition_files/train_sample.csv', dtype=dtypes, parse_dates=['click_time', 'attributed_time'], chunksize=chunk_size):\n",
        "  print(\"Processing chunk #{}\".format(start_index/chunk_size))\n",
        "  train_data = pd.concat([train_data, chunk], sort=False)\n",
        "  for index, row in train_data[start_index:start_index+chunk_size].iterrows():\n",
        "    data_till_now = train_data[:index]\n",
        "\n",
        "    update_count(index, data_till_now, train_data, 'ip', 'clicks_by_ip')\n",
        "    device_count = update_count(index, data_till_now, train_data, 'device', 'clicks_by_device')\n",
        "    update_count(index, data_till_now, train_data, 'os', 'clicks_by_os')\n",
        "    \n",
        "    data_till_now = train_data[:index+1]\n",
        "    \n",
        "    update_attribution_percentage(data_till_now, train_data, 'ip', 'ip_click_attribution_percentage', 'clicks_by_ip')\n",
        "    update_attribution_percentage(data_till_now, train_data, 'device', 'device_click_attribution_percentage', 'clicks_by_device')\n",
        "    update_attribution_percentage(data_till_now, train_data, 'os', 'os_click_attribution_percentage', 'clicks_by_os')\n",
        "  start_index+=chunk_size"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing chunk #0.0\n",
            "Processing chunk #1.0\n",
            "Processing chunk #2.0\n",
            "Processing chunk #3.0\n",
            "Processing chunk #4.0\n",
            "Processing chunk #5.0\n",
            "Processing chunk #6.0\n",
            "Processing chunk #7.0\n",
            "Processing chunk #8.0\n",
            "Processing chunk #9.0\n",
            "Processing chunk #10.0\n",
            "Processing chunk #11.0\n",
            "Processing chunk #12.0\n",
            "Processing chunk #13.0\n",
            "Processing chunk #14.0\n",
            "Processing chunk #15.0\n",
            "Processing chunk #16.0\n",
            "Processing chunk #17.0\n",
            "Processing chunk #18.0\n",
            "Processing chunk #19.0\n",
            "Processing chunk #20.0\n",
            "Processing chunk #21.0\n",
            "Processing chunk #22.0\n",
            "Processing chunk #23.0\n",
            "Processing chunk #24.0\n",
            "Processing chunk #25.0\n",
            "Processing chunk #26.0\n",
            "Processing chunk #27.0\n",
            "Processing chunk #28.0\n",
            "Processing chunk #29.0\n",
            "Processing chunk #30.0\n",
            "Processing chunk #31.0\n",
            "Processing chunk #32.0\n",
            "Processing chunk #33.0\n",
            "Processing chunk #34.0\n",
            "Processing chunk #35.0\n",
            "Processing chunk #36.0\n",
            "Processing chunk #37.0\n",
            "Processing chunk #38.0\n",
            "Processing chunk #39.0\n",
            "Processing chunk #40.0\n",
            "Processing chunk #41.0\n",
            "Processing chunk #42.0\n",
            "Processing chunk #43.0\n",
            "Processing chunk #44.0\n",
            "Processing chunk #45.0\n",
            "Processing chunk #46.0\n",
            "Processing chunk #47.0\n",
            "Processing chunk #48.0\n",
            "Processing chunk #49.0\n",
            "Processing chunk #50.0\n",
            "Processing chunk #51.0\n",
            "Processing chunk #52.0\n",
            "Processing chunk #53.0\n",
            "Processing chunk #54.0\n",
            "Processing chunk #55.0\n",
            "Processing chunk #56.0\n",
            "Processing chunk #57.0\n",
            "Processing chunk #58.0\n",
            "Processing chunk #59.0\n",
            "Processing chunk #60.0\n",
            "Processing chunk #61.0\n",
            "Processing chunk #62.0\n",
            "Processing chunk #63.0\n",
            "Processing chunk #64.0\n",
            "Processing chunk #65.0\n",
            "Processing chunk #66.0\n",
            "Processing chunk #67.0\n",
            "Processing chunk #68.0\n",
            "Processing chunk #69.0\n",
            "Processing chunk #70.0\n",
            "Processing chunk #71.0\n",
            "Processing chunk #72.0\n",
            "Processing chunk #73.0\n",
            "Processing chunk #74.0\n",
            "Processing chunk #75.0\n",
            "Processing chunk #76.0\n",
            "Processing chunk #77.0\n",
            "Processing chunk #78.0\n",
            "Processing chunk #79.0\n",
            "Processing chunk #80.0\n",
            "Processing chunk #81.0\n",
            "Processing chunk #82.0\n",
            "Processing chunk #83.0\n",
            "Processing chunk #84.0\n",
            "Processing chunk #85.0\n",
            "Processing chunk #86.0\n",
            "Processing chunk #87.0\n",
            "Processing chunk #88.0\n",
            "Processing chunk #89.0\n",
            "Processing chunk #90.0\n",
            "Processing chunk #91.0\n",
            "Processing chunk #92.0\n",
            "Processing chunk #93.0\n",
            "Processing chunk #94.0\n",
            "Processing chunk #95.0\n",
            "Processing chunk #96.0\n",
            "Processing chunk #97.0\n",
            "Processing chunk #98.0\n",
            "Processing chunk #99.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tQxNioemMhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a22bc581-a619-468f-8ad5-eca706e1f82d"
      },
      "source": [
        "train_data['is_attributed'].value_counts()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    99773\n",
              "1      227\n",
              "Name: is_attributed, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiVFFn4dMGIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_latest_value_from_train_data(test_data, index, col_name, clicks_col_name, default_value):\n",
        "  col_value = test_data.iloc[index][col_name]\n",
        "  matching_train_data_rows = train_data[train_data[col_name] == col_value]\n",
        "  if matching_train_data_rows.empty:\n",
        "    test_data[clicks_col_name] = default_value\n",
        "  else:\n",
        "    test_data.at[index, clicks_col_name] = matching_train_data_rows[clicks_col_name].iloc[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrxLhamHjYNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3366
        },
        "outputId": "4567c2dd-6d76-4d85-b834-c15096dfa301"
      },
      "source": [
        "dtypes = {  'ip': 'uint16',\n",
        "            'app': 'uint16',\n",
        "            'device': 'uint16',\n",
        "            'os': 'uint16',\n",
        "            'channel': 'uint16'}\n",
        "\n",
        "chunk_size=1000\n",
        "test_data = pd.DataFrame()\n",
        "start_index = 0\n",
        "for chunk in pd.read_csv('test.csv', dtype=dtypes, parse_dates=['click_time'], chunksize=chunk_size):\n",
        "  print(\"Processing chunk #{}\".format(start_index/chunk_size))\n",
        "  test_data = pd.concat([test_data, chunk], sort=False)\n",
        "  for index, row in test_data[start_index:start_index+chunk_size].iterrows():\n",
        "    update_latest_value_from_train_data(test_data, index, 'ip', 'clicks_by_ip', 1)\n",
        "    update_latest_value_from_train_data(test_data, index, 'device', 'clicks_by_device', 1)\n",
        "    update_latest_value_from_train_data(test_data, index, 'os', 'clicks_by_os', 1)\n",
        "    \n",
        "    update_latest_value_from_train_data(test_data, index, 'ip', 'ip_click_attribution_percentage', 0)\n",
        "    update_latest_value_from_train_data(test_data, index, 'device', 'device_click_attribution_percentage', 0)\n",
        "    update_latest_value_from_train_data(test_data, index, 'os', 'os_click_attribution_percentage', 0)\n",
        "  start_index+=chunk_size\n",
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing chunk #0.0\n",
            "Processing chunk #1.0\n",
            "Processing chunk #2.0\n",
            "Processing chunk #3.0\n",
            "Processing chunk #4.0\n",
            "Processing chunk #5.0\n",
            "Processing chunk #6.0\n",
            "Processing chunk #7.0\n",
            "Processing chunk #8.0\n",
            "Processing chunk #9.0\n",
            "Processing chunk #10.0\n",
            "Processing chunk #11.0\n",
            "Processing chunk #12.0\n",
            "Processing chunk #13.0\n",
            "Processing chunk #14.0\n",
            "Processing chunk #15.0\n",
            "Processing chunk #16.0\n",
            "Processing chunk #17.0\n",
            "Processing chunk #18.0\n",
            "Processing chunk #19.0\n",
            "Processing chunk #20.0\n",
            "Processing chunk #21.0\n",
            "Processing chunk #22.0\n",
            "Processing chunk #23.0\n",
            "Processing chunk #24.0\n",
            "Processing chunk #25.0\n",
            "Processing chunk #26.0\n",
            "Processing chunk #27.0\n",
            "Processing chunk #28.0\n",
            "Processing chunk #29.0\n",
            "Processing chunk #30.0\n",
            "Processing chunk #31.0\n",
            "Processing chunk #32.0\n",
            "Processing chunk #33.0\n",
            "Processing chunk #34.0\n",
            "Processing chunk #35.0\n",
            "Processing chunk #36.0\n",
            "Processing chunk #37.0\n",
            "Processing chunk #38.0\n",
            "Processing chunk #39.0\n",
            "Processing chunk #40.0\n",
            "Processing chunk #41.0\n",
            "Processing chunk #42.0\n",
            "Processing chunk #43.0\n",
            "Processing chunk #44.0\n",
            "Processing chunk #45.0\n",
            "Processing chunk #46.0\n",
            "Processing chunk #47.0\n",
            "Processing chunk #48.0\n",
            "Processing chunk #49.0\n",
            "Processing chunk #50.0\n",
            "Processing chunk #51.0\n",
            "Processing chunk #52.0\n",
            "Processing chunk #53.0\n",
            "Processing chunk #54.0\n",
            "Processing chunk #55.0\n",
            "Processing chunk #56.0\n",
            "Processing chunk #57.0\n",
            "Processing chunk #58.0\n",
            "Processing chunk #59.0\n",
            "Processing chunk #60.0\n",
            "Processing chunk #61.0\n",
            "Processing chunk #62.0\n",
            "Processing chunk #63.0\n",
            "Processing chunk #64.0\n",
            "Processing chunk #65.0\n",
            "Processing chunk #66.0\n",
            "Processing chunk #67.0\n",
            "Processing chunk #68.0\n",
            "Processing chunk #69.0\n",
            "Processing chunk #70.0\n",
            "Processing chunk #71.0\n",
            "Processing chunk #72.0\n",
            "Processing chunk #73.0\n",
            "Processing chunk #74.0\n",
            "Processing chunk #75.0\n",
            "Processing chunk #76.0\n",
            "Processing chunk #77.0\n",
            "Processing chunk #78.0\n",
            "Processing chunk #79.0\n",
            "Processing chunk #80.0\n",
            "Processing chunk #81.0\n",
            "Processing chunk #82.0\n",
            "Processing chunk #83.0\n",
            "Processing chunk #84.0\n",
            "Processing chunk #85.0\n",
            "Processing chunk #86.0\n",
            "Processing chunk #87.0\n",
            "Processing chunk #88.0\n",
            "Processing chunk #89.0\n",
            "Processing chunk #90.0\n",
            "Processing chunk #91.0\n",
            "Processing chunk #92.0\n",
            "Processing chunk #93.0\n",
            "Processing chunk #94.0\n",
            "Processing chunk #95.0\n",
            "Processing chunk #96.0\n",
            "Processing chunk #97.0\n",
            "Processing chunk #98.0\n",
            "Processing chunk #99.0\n",
            "Processing chunk #100.0\n",
            "Processing chunk #101.0\n",
            "Processing chunk #102.0\n",
            "Processing chunk #103.0\n",
            "Processing chunk #104.0\n",
            "Processing chunk #105.0\n",
            "Processing chunk #106.0\n",
            "Processing chunk #107.0\n",
            "Processing chunk #108.0\n",
            "Processing chunk #109.0\n",
            "Processing chunk #110.0\n",
            "Processing chunk #111.0\n",
            "Processing chunk #112.0\n",
            "Processing chunk #113.0\n",
            "Processing chunk #114.0\n",
            "Processing chunk #115.0\n",
            "Processing chunk #116.0\n",
            "Processing chunk #117.0\n",
            "Processing chunk #118.0\n",
            "Processing chunk #119.0\n",
            "Processing chunk #120.0\n",
            "Processing chunk #121.0\n",
            "Processing chunk #122.0\n",
            "Processing chunk #123.0\n",
            "Processing chunk #124.0\n",
            "Processing chunk #125.0\n",
            "Processing chunk #126.0\n",
            "Processing chunk #127.0\n",
            "Processing chunk #128.0\n",
            "Processing chunk #129.0\n",
            "Processing chunk #130.0\n",
            "Processing chunk #131.0\n",
            "Processing chunk #132.0\n",
            "Processing chunk #133.0\n",
            "Processing chunk #134.0\n",
            "Processing chunk #135.0\n",
            "Processing chunk #136.0\n",
            "Processing chunk #137.0\n",
            "Processing chunk #138.0\n",
            "Processing chunk #139.0\n",
            "Processing chunk #140.0\n",
            "Processing chunk #141.0\n",
            "Processing chunk #142.0\n",
            "Processing chunk #143.0\n",
            "Processing chunk #144.0\n",
            "Processing chunk #145.0\n",
            "Processing chunk #146.0\n",
            "Processing chunk #147.0\n",
            "Processing chunk #148.0\n",
            "Processing chunk #149.0\n",
            "Processing chunk #150.0\n",
            "Processing chunk #151.0\n",
            "Processing chunk #152.0\n",
            "Processing chunk #153.0\n",
            "Processing chunk #154.0\n",
            "Processing chunk #155.0\n",
            "Processing chunk #156.0\n",
            "Processing chunk #157.0\n",
            "Processing chunk #158.0\n",
            "Processing chunk #159.0\n",
            "Processing chunk #160.0\n",
            "Processing chunk #161.0\n",
            "Processing chunk #162.0\n",
            "Processing chunk #163.0\n",
            "Processing chunk #164.0\n",
            "Processing chunk #165.0\n",
            "Processing chunk #166.0\n",
            "Processing chunk #167.0\n",
            "Processing chunk #168.0\n",
            "Processing chunk #169.0\n",
            "Processing chunk #170.0\n",
            "Processing chunk #171.0\n",
            "Processing chunk #172.0\n",
            "Processing chunk #173.0\n",
            "Processing chunk #174.0\n",
            "Processing chunk #175.0\n",
            "Processing chunk #176.0\n",
            "Processing chunk #177.0\n",
            "Processing chunk #178.0\n",
            "Processing chunk #179.0\n",
            "Processing chunk #180.0\n",
            "Processing chunk #181.0\n",
            "Processing chunk #182.0\n",
            "Processing chunk #183.0\n",
            "Processing chunk #184.0\n",
            "Processing chunk #185.0\n",
            "Processing chunk #186.0\n",
            "Processing chunk #187.0\n",
            "Processing chunk #188.0\n",
            "Processing chunk #189.0\n",
            "Processing chunk #190.0\n",
            "Processing chunk #191.0\n",
            "Processing chunk #192.0\n",
            "Processing chunk #193.0\n",
            "Processing chunk #194.0\n",
            "Processing chunk #195.0\n",
            "Processing chunk #196.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW2s3-pf4d-w",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8N8Xqce4d-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def percentage_plot(ax, height):\n",
        "    ax.set_alpha(0.8)\n",
        "    ax.tick_params(axis='both', which='both', length=0)\n",
        "\n",
        "    total_height = 0\n",
        "    for i in ax.patches:\n",
        "        total_height += i.get_height()\n",
        "\n",
        "    for i in ax.patches:\n",
        "        ax.text(i.get_x(), i.get_height()+height, \\\n",
        "                str(round((i.get_height()/total_height)*100, 2))+'%', fontsize=15,\n",
        "                    color='dimgrey')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6jbfO5n4d-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.box(on=None)\n",
        "\n",
        "cols = ['app', 'device', 'os', 'channel']\n",
        "uniques = [len(train_data[col].unique()) for col in cols]\n",
        "\n",
        "ax.bar(cols, uniques)\n",
        "ax.set_xlabel('Number of unique values per feature')\n",
        "\n",
        "percentage_plot(ax, 1.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72EiD_og4d_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.box(on=None)\n",
        "\n",
        "mean = (train_data.is_attributed.values == 1).mean()\n",
        "ax.bar(['Downloaded (1)', 'Not Downloaded (0)'], [mean, 1-mean])\n",
        "ax.set(ylabel='Proportion', title='App Downloaded vs Not Downloaded')\n",
        "percentage_plot(ax, 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSB5y02v4d_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.box(on=None)\n",
        "plt.title('')\n",
        "\n",
        "\n",
        "\n",
        "plt.bar(cols, uniques)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6y9VBne4d_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# is_attributed_true = train_data[train_data['is_attributed'] == 1]\n",
        "# is_attributed_false = train_data[train_data['is_attributed'] == 0]\n",
        "\n",
        "# grouped_data = train_data.groupby(['ip', 'is_attributed'], as_index=False).count().sort_values(by=['ip'], ascending=False)\n",
        "\n",
        "# grouped_data.reset_index()\n",
        "# grouped_data[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmUNmaQQga_O",
        "colab": {}
      },
      "source": [
        "plt.hist(train_data['ip'], bins=4)\n",
        "plt.box(on=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osrw9mZ4memw",
        "colab_type": "text"
      },
      "source": [
        "The above chart tells us that IP with lesser values are used more. For example, IP values between range of 0 to 100000 were used the most. So the IPs seem to be sorted by how frequently they were used. Lets see how the IP to attribution ratio is in the below charts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V-f4VEeQgao3",
        "colab": {}
      },
      "source": [
        "ip_with_attributed_time = train_data[train_data['attributed_time'].notna()]['ip']\n",
        "plt.hist(ip_with_attributed_time, bins=4) \n",
        "plt.box(on=None)\n",
        "\n",
        "print('Total unique IPs having attributed time = ', len(ip_with_attributed_time.unique()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrWbjHG58mc9",
        "colab_type": "text"
      },
      "source": [
        "The maximum number of times an ad has been clicked from IPs that resulted in mobile download is 60.The previous graph tells us that IPs that did not result in app downloads were used more than 50,000 times!\n",
        "Let us now see total number of times IPs that resulted in app download also did not result in download. That is, common IPs with and without attributed time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTRS2wex-pgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ip_without_attributed_time = train_data[train_data['attributed_time'].isna()]['ip']\n",
        "# ips_with_both = pd.Series(list(set(ip_with_attributed_time) & set(ip_without_attributed_time)))\n",
        "\n",
        "common_ips_with_and_without_attribution = train_data[train_data['ip'].isin(ip_with_attributed_time)]['ip']\n",
        "plt.hist(common_ips_with_and_without_attribution, bins=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt6CO2hk6uNl",
        "colab_type": "text"
      },
      "source": [
        "We can observe that the ips frequency that resulted in both attribution and non-attribution does not exceed 1600. From the above graphs, we can conclude that valid IPs for any dataset that result in successful downloads are not used more than 1600 times.\n",
        "\n",
        "We might have to come up with similar comparison of IPs to os, app, device, channel, click_time to be able to put IPs into buckets better.\n",
        "\n",
        "NOTES FOR ME: Condense results into single graph with 3 rows and add reusuable method for each field. Update results for undersampled training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir9khQz84d-x",
        "colab_type": "text"
      },
      "source": [
        "```ip, app, device, os and channel``` are actually categorical variables encoded as integers. Set them as categories for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfdumucRpUME",
        "colab_type": "text"
      },
      "source": [
        "# Feature Engineering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O90k0BLu4d-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_categoricial(data, columns):\n",
        "  for col_name in columns:\n",
        "    data[col_name] = data[col_name].astype('category')\n",
        "\n",
        "convert_to_categoricial(train_data, ['ip', 'app', 'device', 'os', 'channel', 'is_attributed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3e5eaFD4d_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting time information\n",
        "\n",
        "def extract_day_minute_hour(data, column_name):\n",
        "  # Convert date stamps to date/time stamps\n",
        "  data[column_name] = pd.to_datetime(data[column_name])\n",
        "\n",
        "  data['day'] = data[column_name].dt.day.astype('uint8')\n",
        "  data['hour'] = data[column_name].dt.hour.astype('uint8')\n",
        "  data['minute'] = data[column_name].dt.minute.astype('uint8')\n",
        "  data['second'] = data[column_name].dt.second.astype('uint8')\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx6A5xRk3lhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extract_day_minute_hour(train_data, 'click_time')\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Mt5Xlu1tda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extract_day_minute_hour(test_data, 'click_time')\n",
        "convert_to_categoricial(test_data, ['ip', 'app', 'device', 'os', 'channel'])\n",
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7kOm4_S4d-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_gtOdeadBep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o1zMEB7Mz_0",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M32eRQm6pkBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "features = ['ip', 'app', 'device', 'os', 'channel', 'day', 'hour', 'minute', 'second']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd_iCZVbM8ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The dataset is highly imbalanced\n",
        "train_data['is_attributed'].value_counts().reset_index().replace({'index': {0:'not converted (can be fraud)', 1:'converted'}})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbTfbc8BkZ4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dealing with imbalanced datasets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kBGjbXwvHb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = LogisticRegression().fit(train_data[features], train_data['is_attributed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AOc6-ee4Wpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict the probability that the app was downloaded\n",
        "test_data['is_attributed'] = clf.predict_proba(test_data[features])[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B4afCDJ5Hcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data['is_attributed'].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkk0JQ1w6A5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_cols = ['click_id', 'is_attributed']\n",
        "test_data[sub_cols].to_csv('submission.csv', index=False)\n",
        "!kaggle competitions submit -c talkingdata-adtracking-fraud-detection -f submission.csv -m \"Test submission 3\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQJXo_uS7tlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}